{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9361de-d5db-4496-ab0e-3efbe36990f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ANNDataPrep\n",
    "import tensorflow as tf\n",
    "# import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffb05aa-4543-458f-b453-a0849fab161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 230.3761019706726 seconds ---\n",
      "(373925, 12, 13)\n",
      "(373925, 13)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMyData/Extracted Data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m ANNDataPrep\u001b[38;5;241m.\u001b[39mpreprocessData(input_sequence_length, forecast_horizon, features, path)\n\u001b[1;32m----> 4\u001b[0m numpy\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, X, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m numpy\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m y[:,\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m7\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_sequence_length = 12\n",
    "forecast_horizon = 12     # 24 = 2 hr,    12 = 1 hr,     6 = 30 min\n",
    "features = 13\n",
    "path = \"D:\\MyData/Extracted Data\"\n",
    "X, y = ANNDataPrep.preprocessData(input_sequence_length, forecast_horizon, features, path)\n",
    "# np.savetxt(\"X.csv\", X, delimiter=\",\")\n",
    "# np.savetxt(\"y.csv\", y, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2dfef3-e563-4597-9932-7ed3ea0b5622",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 1D or 2D array, got 3D array instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, X, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m y[:,\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m7\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1570\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;66;03m# Handle 1-dimensional arrays\u001b[39;00m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1570\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1571\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 1D or 2D array, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mD array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m X\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1573\u001b[0m     \u001b[38;5;66;03m# Common case -- 1d array of numbers\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 1D or 2D array, got 3D array instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# np.savetxt(\"X.csv\", X, delimiter=\",\")\n",
    "# np.savetxt(\"y.csv\", y, delimiter=\",\")\n",
    "y = y[:,5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a79471-4710-47fc-b421-afe4f77350c0",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print(\"X_train size: \" + str(X_train.shape))\n",
    "print(\"y_train size: \" + str(y_train.shape))\n",
    "print(\"X_val size: \" + str(X_val.shape))\n",
    "print(\"y_val size: \" + str(y_val.shape))\n",
    "print(\"X_test size: \" + str(X_test.shape))\n",
    "print(\"y_test size: \" + str(y_test.shape))\n",
    "# numpy.savetxt(\"X_train.csv\", X_train, delimiter=\",\")\n",
    "# numpy.savetxt(\"y_train.csv\", y_train, delimiter=\",\")\n",
    "# numpy.savetxt(\"X_val.csv\", X_val, delimiter=\",\")\n",
    "# numpy.savetxt(\"y_val.csv\", y_val, delimiter=\",\")\n",
    "# numpy.savetxt(\"X_test.csv\", X_test, delimiter=\",\")\n",
    "# numpy.savetxt(\"y_test.csv\", y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce72a8-e3b7-4c91-b222-f30fd376d8b3",
   "metadata": {},
   "source": [
    "## Determine what params to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe87ccf5-ea0a-4153-9b46-994d0e0a2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train[:,5:7]\n",
    "# y_val = y_val[:,5:7]\n",
    "# y_test = y_test[:,5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e41a610-539d-456a-9baa-9c6156c26599",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    num_predicted = y_train.shape[1]\n",
    "except TypeError:\n",
    "    num_predicted = 1\n",
    "# print(num_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f17ef-4f7d-49f1-9400-dc0c7bd677fc",
   "metadata": {},
   "source": [
    "## Create Model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07da99d3-9f4e-4124-b009-c4f812330dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/61931629/overfitting-in-lstm-even-after-using-regularizers\n",
    "# # def create_model():\n",
    "# model = tf.keras.models.Sequential()\n",
    "# # model.add(tf.keras.layers.LSTM(128, return_sequences=False, dropout=0.15, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(tf.keras.layers.LSTM(32, return_sequences=True, dropout=0.30, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(tf.keras.layers.LSTM(32, return_sequences=True, dropout=0.30, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(tf.keras.layers.LSTM(16, return_sequences=True, dropout=0.30, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(tf.keras.layers.LSTM(8, return_sequences=False, dropout=0.30, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# # model.add(tf.keras.layers.Dense(64, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.1)))\n",
    "# # model.add(tf.keras.layers.Dense(64, activation='tanh'))\n",
    "# model.add(tf.keras.layers.Dense(32, activation='linear'))\n",
    "# model.add(tf.keras.layers.Dense(num_predicted, activation='linear'))\n",
    "# # model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# model.summary()\n",
    "#     # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73aa4d24-2e10-43d1-b454-1177a03494c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# batch_size = 128\n",
    "# model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), batch_size=batch_size, verbose=1)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f1bc2-a4c8-4067-bf31-b17b7b4e8b74",
   "metadata": {},
   "source": [
    "# Model I am Using\n",
    "### With 5 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2d1fdb-0df3-44b6-8bd8-cc03985c2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/61931629/overfitting-in-lstm-even-after-using-regularizers\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(128, return_sequences=False, dropout=0.15, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(tf.keras.layers.Dense(num_predicted, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "# start_time = time.time()\n",
    "batch_size = 128\n",
    "# model.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val), batch_size=batch_size, verbose=1)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be5c44-a3aa-4a89-9a28-3adc5b080c87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m72,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m258\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,962</span> (285.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m72,962\u001b[0m (285.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,962</span> (285.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m72,962\u001b[0m (285.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 34ms/step - loss: 0.6054 - mse: 0.6571\n",
      "Epoch 2/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 34ms/step - loss: 0.5142 - mse: 0.5173\n",
      "Epoch 3/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 34ms/step - loss: 0.4915 - mse: 0.4831\n",
      "Epoch 4/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 34ms/step - loss: 0.4808 - mse: 0.4661\n",
      "Epoch 5/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 34ms/step - loss: 0.4720 - mse: 0.4520\n",
      "Epoch 6/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 34ms/step - loss: 0.4650 - mse: 0.4415\n",
      "Epoch 7/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 33ms/step - loss: 0.4605 - mse: 0.4344\n",
      "Epoch 8/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 34ms/step - loss: 0.4556 - mse: 0.4268\n",
      "Epoch 9/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 33ms/step - loss: 0.4524 - mse: 0.4216\n",
      "Epoch 10/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 33ms/step - loss: 0.4504 - mse: 0.4191\n",
      "Epoch 11/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 31ms/step - loss: 0.4464 - mse: 0.4124\n",
      "Epoch 12/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 34ms/step - loss: 0.4427 - mse: 0.4061\n",
      "Epoch 13/50\n",
      "\u001b[1m2338/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 35ms/step - loss: 0.4425 - mse: 0.4066\n",
      "Epoch 14/50\n",
      "\u001b[1m1877/2338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m15s\u001b[0m 33ms/step - loss: 0.4398 - mse: 0.4040"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_new, X_val = X[train_index], X[val_index]\n",
    "    y_train_new, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(X_train_new, y_train_new, epochs=50, batch_size=batch_size, verbose=1)\n",
    "    val_loss = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f'Fold {fold_no} - Validation Loss: {val_loss}')\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3a10c-8bc7-4193-8977-19259050f9d6",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca81db-d563-4569-a3ad-381a123d538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "# print(trainScore)\n",
    "# testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b7018-4622-4d89-b8cf-3576da2f09bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/61931629/overfitting-in-lstm-even-after-using-regularizers\n",
    "# def create_model():\n",
    "#     model = tf.keras.models.Sequential()\n",
    "#     model.add(tf.keras.layers.LSTM(128, return_sequences=False, dropout=0.15, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "#     model.add(tf.keras.layers.Dense(num_predicted, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='huber', metrics=['mse'])\n",
    "#     model.summary()\n",
    "# return model\n",
    "# start_time = time.time()\n",
    "# batch_size = 64\n",
    "# model.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val), batch_size=batch_size, verbose=1)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e7676-4923-4f5c-b43e-915b35da2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "# print(trainScore)\n",
    "# testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d1034-5103-432a-bc29-32326850af0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
